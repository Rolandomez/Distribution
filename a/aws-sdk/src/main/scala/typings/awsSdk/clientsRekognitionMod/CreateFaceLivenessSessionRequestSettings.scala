package typings.awsSdk.clientsRekognitionMod

import org.scalablytyped.runtime.StObject
import scala.scalajs.js
import scala.scalajs.js.annotation.{JSGlobalScope, JSGlobal, JSImport, JSName, JSBracketAccess}

trait CreateFaceLivenessSessionRequestSettings extends StObject {
  
  /**
    * Number of audit images to be returned back. Takes an integer between 0-4. Any integer less than 0 will return 0, any integer above 4 will return 4 images in the response. By default, it is set to 0. The limit is best effort and is based on the actual duration of the selfie-video.
    */
  var AuditImagesLimit: js.UndefOr[typings.awsSdk.clientsRekognitionMod.AuditImagesLimit] = js.undefined
  
  /**
    * Can specify the location of an Amazon S3 bucket, where reference and audit images will be stored. Note that the Amazon S3 bucket must be located in the caller's AWS account and in the same region as the Face Liveness end-point. Additionally, the Amazon S3 object keys are auto-generated by the Face Liveness system. Requires that the caller has the s3:PutObject permission on the Amazon S3 bucket.
    */
  var OutputConfig: js.UndefOr[LivenessOutputConfig] = js.undefined
}
object CreateFaceLivenessSessionRequestSettings {
  
  inline def apply(): CreateFaceLivenessSessionRequestSettings = {
    val __obj = js.Dynamic.literal()
    __obj.asInstanceOf[CreateFaceLivenessSessionRequestSettings]
  }
  
  @scala.inline
  implicit open class MutableBuilder[Self <: CreateFaceLivenessSessionRequestSettings] (val x: Self) extends AnyVal {
    
    inline def setAuditImagesLimit(value: AuditImagesLimit): Self = StObject.set(x, "AuditImagesLimit", value.asInstanceOf[js.Any])
    
    inline def setAuditImagesLimitUndefined: Self = StObject.set(x, "AuditImagesLimit", js.undefined)
    
    inline def setOutputConfig(value: LivenessOutputConfig): Self = StObject.set(x, "OutputConfig", value.asInstanceOf[js.Any])
    
    inline def setOutputConfigUndefined: Self = StObject.set(x, "OutputConfig", js.undefined)
  }
}
